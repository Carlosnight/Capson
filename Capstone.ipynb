{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于卷积神经网络实现猫狗识别\n",
    "\n",
    "下载数据集到本地，[链接](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data),下载方法可见 README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据导入与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\yeyiy\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from keras.utils import np_utils\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义调用模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取训练数据和验证数据模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = 'C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe'\n",
    "TEST_DATA_DIR = 'C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe'\n",
    "\n",
    "def create_image_list():\n",
    "    train_input = []\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DATA_DIR)):\n",
    "        images = os.path.join(TRAIN_DATA_DIR, img)\n",
    "        train_images.append(images)\n",
    "#         display(Image.open(TRAIN_DATA_DIR+'/'+img))\n",
    "\n",
    "        labels = img.split('.')[0]\n",
    "        if labels == 'cat':\n",
    "            train_labels.append(0)\n",
    "        else:\n",
    "            train_labels.append(1)\n",
    "            \n",
    "    for img in tqdm(os.listdir(TEST_DATA_DIR)):\n",
    "        images = os.path.join(TEST_DATA_DIR, img)\n",
    "        test_images.append(images)\n",
    "            \n",
    "    #         images = cv2.imread(images, cv2.IMREAD_COLOR)\n",
    "#         images = image.load_img(images, target_size=(10,10))\n",
    "#         print(type(images))\n",
    "#         images = image.img_to_array(images)\n",
    "    \n",
    "    \n",
    "    train_input = np.array([train_images, train_labels])\n",
    "    train_input = train_input.transpose()\n",
    "    np.random.shuffle(train_input)\n",
    "    np.save('train_input.npy', train_input)\n",
    "    \n",
    "    t_images, v_images, t_labels, v_labels = train_test_split(\n",
    "        train_images, train_labels, test_size=0.20, random_state=0)\n",
    "    \n",
    "    return t_images, t_labels, v_images, v_labels, test_images\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成器输出模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(i_images, i_labels, image_size):\n",
    "\n",
    "    input_images = []\n",
    "    \n",
    "    for i_img in i_images:\n",
    "#       images = cv2.imread(images, cv2.IMREAD_COLOR)\n",
    "        images = image.load_img(i_img, target_size=(1,image_size,image_size, 3))\n",
    "        images = image.img_to_array(images)\n",
    "        input_images.append(images)\n",
    "    input_images = np.array(input_images)\n",
    "    \n",
    "    # one hot eencoding\n",
    "    input_labels = np_utils.to_categorical(i_labels)\n",
    "    \n",
    "    \n",
    "    # 图像预处理\n",
    "    datagen = image.ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "    \n",
    "    datagen.fit(t_images, seed=10)\n",
    "    train_batch = datagen.flow(input_images, input_labels,\n",
    "                                 batch_size=64,shuffle=True,\n",
    "                                 seed=10)\n",
    "    \n",
    "#     for x,y in train_batch:\n",
    "#         print(y)\n",
    "    \n",
    "    return train_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_batch(i_images, image_szie):\n",
    "    input_images = []\n",
    "    \n",
    "    for i_img in i_images:\n",
    "#       images = cv2.imread(images, cv2.IMREAD_COLOR)\n",
    "        images = image.load_img(i_img, target_size=(1,image_size,image_size, 3))\n",
    "        images = image.img_to_array(images)\n",
    "        input_images.append(images)\n",
    "    input_images = np.array(input_images)\n",
    "    \n",
    "    # 图像预处理\n",
    "    datagen = image.ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "    \n",
    "    datagen.fit(t_images, seed=10)\n",
    "    test_batch = datagen.flow(input_images,shuffle=False,batch_size=64)\n",
    "    \n",
    "#     for x,y in train_batch:\n",
    "#         print(y)\n",
    "    \n",
    "    return test_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果可视化模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(t_history,train,valid):\n",
    "    plt.plot(t_history.history[train])\n",
    "    plt.plot(t_history.history[valid])\n",
    "    plt.title('Xception Model '+ train +' History')\n",
    "    plt.y_label(train)\n",
    "    plt.x_label('Epoch')\n",
    "    plt.legend(['train '+train, 'valid '+valid], loc='upper left')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型\n",
    "使用预训练过的模型，使用迁移学习的思想进行模型的建立，并试图进行模型融合训练，使用到的模型有\n",
    "- Inception v3\n",
    "- InceptionResNetV2\n",
    "- Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kears.applications.Xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from IPython.display import SVG\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = Xception(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "\n",
    "for layer in model_xception.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = GlobalAveragePooling2D()(model_xception.output)\n",
    "\n",
    "model1 = Flatten(name='flatten')(x)\n",
    "model1 = Dense(4096, activation='relu', name='fc1')(model1)\n",
    "model1 = Dense(4096, activation='relu', nmae='fc2')(model1)\n",
    "model1 = Dropout(0.5)(model1)\n",
    "model1 = Dense(2, activation='softmax', name='prediction')(model1)\n",
    "\n",
    "model_xception_pred = Model(model_xception.input, model1, name='xception')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 选择损失函数(loss)为：categorical_crossentropy  \n",
    "- 选择优化器(optimizer)为：Nadam() \n",
    "- 选择评价函数为：accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception_pred.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "image_size = 299\n",
    "\n",
    "t_images, t_labels, v_images, v_labels, test_images = create_image_list()\n",
    "x_t_generator = make_batch(t_images, t_labels, image_size)\n",
    "x_v_generator = make_batch(v_images, v_labels, image_size)\n",
    "x_test_generator = make_test_batch(test_images, image_size)\n",
    "xception_history = model_xception_pred.fit_generator(x_t_generator, epochs=epochs, verbose=1, validation_data=x_v_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model_xception_pred, show_shapes=True).create(prog=\"dot\", format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy 可视化\n",
    "show_history(xception_history, 'acc', 'val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 可视化\n",
    "show_history(xception_history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立混合模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = Xception(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "x = GlobalAveragePooling2D()(model_xception.output)\n",
    "xception_model = Model(model_xception.input, x)\n",
    "\n",
    "xception_train = xception_model.predict_generate(x_t_generator)\n",
    "xception_valid = xception_model.predict_generate(x_v_generator)\n",
    "xception_test = xception_model.predict_generator(x_test_generator)\n",
    "\n",
    "# 将特征向量写入数据文件\n",
    "with h5py.File(\"gap_Xception.h5\") as h:\n",
    "    h.create_dataset(\"train\", data=xception_train)\n",
    "    h.create_dataset(\"valid\", data=xception_valid)\n",
    "    h.create_dataset(\"test\", data=xception_test)\n",
    "    h.create_dataset(\"t_label\", data=x_t_generator.classes)\n",
    "    h.create_dataset(\"v_label\", data=x_v_generator.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception v3 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception_v3 = InceptionV3(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "y = GlobalAveragePooling2D()(model_inception_v3.output)\n",
    "inceptionV3_model = Model(model_inception_v3.input, y)\n",
    "\n",
    "inceptionV3_train = inceptionV3_model.predict_generate(x_t_generator)\n",
    "inceptionV3_valid = inceptionV3_model.predict_generate(x_v_generator)\n",
    "inceptionV3_test = inceptionV3_model.predict_generator(x_test_generator)\n",
    "\n",
    "# 将特征向量写入数据文件\n",
    "with h5py.File(\"gap_InceptionV3.h5\") as h:\n",
    "    h.create_dataset(\"train\", data=inceptionV3_train)\n",
    "    h.create_dataset(\"valid\", data=inceptionV3_valid)\n",
    "    h.create_dataset(\"test\", data=inceptionV3_test)\n",
    "    h.create_dataset(\"t_label\", data=x_t_generator.classes)\n",
    "    h.create_dataset(\"v_label\", data=x_v_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionresnetv2 = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "z = GlobalAveragePooling2D()(model_inceptionresnetv2.output)\n",
    "inceptionresnetv2_model = Model(model_inceptionresnetv2.input, y)\n",
    "\n",
    "inceptionresnetv2_train = inceptionresnetv2_model.predict_generate(x_t_generator)\n",
    "inceptionresnetv2_valid = inceptionresnetv2_model.predict_generate(x_v_generator)\n",
    "inceptionresnetv2_test = inceptionresnetv2_model.predict_generator(x_test_generator)\n",
    "\n",
    "# 将特征向量写入数据文件\n",
    "with h5py.File(\"gap_InceptionResNetV2.h5\") as h:\n",
    "    h.create_dataset(\"train\", data=inceptionresnetv2_train)\n",
    "    h.create_dataset(\"valid\", data=inceptionresnetv2_valid)\n",
    "    h.create_dataset(\"test\", data=inceptionresnetv2_test)\n",
    "    h.create_dataset(\"t_label\", data=x_t_generator.classes)\n",
    "    h.create_dataset(\"v_label\", data=x_v_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从文件中读取特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "valid_images = []\n",
    "valid_labels = []\n",
    "test_data = []\n",
    "\n",
    "h5File = [\"gap_Xception.h5\", \"gap_InceptionV3.h5\", \"gap_InceptionResNetV2.h5\"]\n",
    "for filename in h5File:\n",
    "    for h5py.File(filename, 'r') as h:\n",
    "        train_images.append(np.array(h['train']))\n",
    "        train_labels.append(np.array(h['t_label']))\n",
    "        valid_images.append(np.array(h['valid']))\n",
    "        valid_labels.append(np.array(h['v_label']))\n",
    "        test_data.append(np.array(h['test']))\n",
    "        \n",
    "# 将list竖直拼接\n",
    "train_images = np.concatenate(train_images, axis=1)\n",
    "train_labels = np.concatenate(train_labels, axis=1)\n",
    "valid_images = np.concatenate(valid_images, axis=1)\n",
    "valid_labels = np.concatenate(valid_labels, axis=1)\n",
    "test_data = np.concatenate(test_data, axis=1)\n",
    "\n",
    "train_images, train_labels = shuffle(train_images, train_labels)\n",
    "valid_images, valid_labels = shuffle(valid_images, valid_labels)\n",
    "valid_data = np.array(tuple([valid_images, valid_labels]))\n",
    "valid_data = valid_data.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = Input(train_images.shape[1:])\n",
    "\n",
    "model = Dropout(0.5)(train_input)\n",
    "model = Dense(1, activation='sigmoid')(model)\n",
    "\n",
    "new_model = Model(train_input, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(train_images, train_labels, batch_size=128, epochs=10, verbose=2, validation_data=valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = new_model.predict(test_data, verbose=1)\n",
    "test_pred = test_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "file = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(TEST_DATA_DIR, (299, 299),\n",
    "                                        shuffle=False, batch_size=16, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1 : fname.rfind('.')])\n",
    "    file.set_value(index-1, 'label', test_pred[i])\n",
    "    \n",
    "file.to_csv('pred.csv', index=None)\n",
    "file.head(10)\n",
    "\n",
    "# _1, _2, _3, _4, test_images = create_image_list()\n",
    "\n",
    "# for filename in enumerate(test_images):\n",
    "#     i = 0\n",
    "#     filename_with_null = filename.replace(TEST_DATA_DIR+\"/\",\"\")\n",
    "#     index = file_name_with_null.split(\".\")[0]\n",
    "#     file.set_value(index, 'label', test_pred[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
