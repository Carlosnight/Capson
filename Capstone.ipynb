{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于卷积神经网络实现猫狗识别\n",
    "\n",
    "下载数据集到本地，[链接](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data),下载方法可见 README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据导入与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\yeyiy\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from keras.utils import np_utils\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义调用模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 制作软连接模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = 'C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe'\n",
    "TEST_DATA_DIR = 'C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe'\n",
    "\n",
    "def make_symlink():\n",
    "\n",
    "    image_dogs = []\n",
    "    image_cats = []\n",
    "    label_dogs = []\n",
    "    label_cats = []\n",
    "    test_images = []\n",
    "    \n",
    "    if not os.path.exists(TRAIN_DATA_DIR+'/newTrain'):\n",
    "    os.mkdir('newTrain')\n",
    "    os.mkdir('newTrain/cats')\n",
    "    os.mkdir('newTrain/dogs')\n",
    "    if not os.path.exists(TRAIN_DATA_DIR+'/newTrain'):\n",
    "    os.mkdir('newTest')\n",
    "    \n",
    "    \n",
    "    for img in tqdm(os.listdir(TRAIN_DATA_DIR)):\n",
    "        images = os.path.join(img)\n",
    "#         display(Image.open(TRAIN_DATA_DIR+'/'+img))\n",
    "\n",
    "        labels = img.split('.')[0]\n",
    "        if labels == 'cat':\n",
    "            image_cats.append(images)\n",
    "            label_cats.append(0)\n",
    "        else:\n",
    "            image_dogs.append(images)\n",
    "            label_dogs.append(1)\n",
    "            \n",
    "    for img in tqdm(os.listdir(TEST_DATA_DIR)):\n",
    "        images = os.path.join(img)\n",
    "        test_images.append(images)\n",
    "            \n",
    "    for filename in image_cats:\n",
    "        os.symlink('../../train/'+filename, 'newTrain/cat/'+filename)\n",
    "        \n",
    "    for filename in image_dogs:\n",
    "        os.symlink('../../train/'+filename, 'newTrain/dog/'+filename)\n",
    "    \n",
    "    os.sumlink('../test/', 'newTest/test')\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成器输出模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(image_size):\n",
    "\n",
    "#     input_images = []\n",
    "    \n",
    "#     for i_img in i_images:\n",
    "# #       images = cv2.imread(images, cv2.IMREAD_COLOR)\n",
    "#         images = image.load_img(i_img, target_size=(1,image_size,image_size, 3))\n",
    "#         images = image.img_to_array(images)\n",
    "#         input_images.append(images)\n",
    "#     input_images = np.array(input_images)\n",
    "    \n",
    "#     # one hot eencoding\n",
    "#     input_labels = np_utils.to_categorical(i_labels)\n",
    "    \n",
    "    \n",
    "    # 图像预处理\n",
    "    datagen = image.ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "    \n",
    "    train_batch = datagen.flow_from_directory('newTrain', target_size=(image_size,image_size),\n",
    "                                 batch_size=64,shuffle=False,seed=10)\n",
    "    \n",
    "    test_batch = datagen.flow_from_directory('newTest', target_size=(image_size, image_size),\n",
    "                                 batch_size=64, shuffle=False,class_mode=None, seed=10)\n",
    "    \n",
    "    return train_batch, test_batch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结果可视化模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(t_history,train,valid):\n",
    "    plt.plot(t_history.history[train])\n",
    "    plt.plot(t_history.history[valid])\n",
    "    plt.title('Xception Model '+ train +' History')\n",
    "    plt.y_label(train)\n",
    "    plt.x_label('Epoch')\n",
    "    plt.legend(['train '+train, 'valid '+valid], loc='upper left')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型\n",
    "使用预训练过的模型，使用迁移学习的思想进行模型的建立，并试图进行模型融合训练，使用到的模型有\n",
    "- Inception v3\n",
    "- InceptionResNetV2\n",
    "- Xception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kears.applications.Xception import Xception\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from IPython.display import SVG\n",
    "import h5py as h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = Xception(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "\n",
    "for layer in model_xception.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = GlobalAveragePooling2D()(model_xception.output)\n",
    "\n",
    "model1 = Flatten(name='flatten')(x)\n",
    "model1 = Dense(4096, activation='relu', name='fc1')(model1)\n",
    "model1 = Dense(4096, activation='relu', nmae='fc2')(model1)\n",
    "model1 = Dropout(0.5)(model1)\n",
    "model1 = Dense(2, activation='softmax', name='prediction')(model1)\n",
    "\n",
    "model_xception_pred = Model(model_xception.input, model1, name='xception')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 选择损失函数(loss)为：categorical_crossentropy  \n",
    "- 选择优化器(optimizer)为：Nadam() \n",
    "- 选择评价函数为：accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception_pred.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "image_size = 299\n",
    "\n",
    "make_symlink()\n",
    "train_generator, test_generator = make_generator(image_size)\n",
    "xception_history = model_xception_pred.fit_generator(train_generator, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model_xception_pred, show_shapes=True).create(prog=\"dot\", format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 执行结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy 可视化\n",
    "show_history(xception_history, 'acc', 'val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 可视化\n",
    "show_history(xception_history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立混合模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = Xception(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "x = GlobalAveragePooling2D()(model_xception.output)\n",
    "xception_model = Model(model_xception.input, x)\n",
    "\n",
    "xception_train = xception_model.predict_generate(train_generator)\n",
    "xception_test = xception_model.predict_generator(test_generator)\n",
    "\n",
    "# 将特征向量写入数据文件\n",
    "with h5py.File(\"gap_Xception.h5\") as h:\n",
    "    h.create_dataset(\"train\", data=xception_train)\n",
    "    h.create_dataset(\"test\", data=xception_test)\n",
    "    h.create_dataset(\"t_label\", data=train_generator.classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception v3 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception_v3 = InceptionV3(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "y = GlobalAveragePooling2D()(model_inception_v3.output)\n",
    "inceptionV3_model = Model(model_inception_v3.input, y)\n",
    "\n",
    "inceptionV3_train = inceptionV3_model.predict_generate(train_generator)\n",
    "inceptionV3_test = inceptionV3_model.predict_generator(test_generator)\n",
    "\n",
    "# 将特征向量写入数据文件\n",
    "with h5py.File(\"gap_InceptionV3.h5\") as h:\n",
    "    h.create_dataset(\"train\", data=inceptionV3_train)\n",
    "    h.create_dataset(\"test\", data=inceptionV3_test)\n",
    "    h.create_dataset(\"t_label\", data=train_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionResNetV2 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionresnetv2 = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(299,299,3))\n",
    "z = GlobalAveragePooling2D()(model_inceptionresnetv2.output)\n",
    "inceptionresnetv2_model = Model(model_inceptionresnetv2.input, y)\n",
    "\n",
    "inceptionresnetv2_train = inceptionresnetv2_model.predict_generate(train_generator)\n",
    "inceptionresnetv2_test = inceptionresnetv2_model.predict_generator(test_generator)\n",
    "\n",
    "# 将特征向量写入数据文件\n",
    "with h5py.File(\"gap_InceptionResNetV2.h5\") as h:\n",
    "    h.create_dataset(\"train\", data=inceptionresnetv2_train)\n",
    "    h.create_dataset(\"test\", data=inceptionresnetv2_test)\n",
    "    h.create_dataset(\"t_label\", data=train_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从文件中读取特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "valid_images = []\n",
    "valid_labels = []\n",
    "test_data = []\n",
    "\n",
    "h5File = [\"gap_Xception.h5\", \"gap_InceptionV3.h5\", \"gap_InceptionResNetV2.h5\"]\n",
    "for filename in h5File:\n",
    "    for h5py.File(filename, 'r') as h:\n",
    "        train_images.append(np.array(h['train']))\n",
    "        train_labels.append(np.array(h['t_label']))\n",
    "        test_data.append(np.array(h['test']))\n",
    "        \n",
    "# 将list竖直拼接\n",
    "train_images = np.concatenate(train_images, axis=1)\n",
    "# train_labels = np.concatenate(train_labels, axis=1)\n",
    "test_data = np.concatenate(test_data, axis=1)\n",
    "\n",
    "train_images, train_labels = shuffle(train_images, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = Input(train_images.shape[1:])\n",
    "\n",
    "model = Dropout(0.5)(train_input)\n",
    "model = Dense(1, activation='sigmoid')(model)\n",
    "\n",
    "new_model = Model(train_input, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(loss='categorical_crossentropy', optimizer=Nadam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(train_images, train_labels, batch_size=128, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = new_model.predict(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "file = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "test_generator = gen.flow_from_directory(TEST_DATA_DIR, (299, 299),\n",
    "                                        shuffle=False, batch_size=16, class_mode=None)\n",
    "\n",
    "for i, filename in enumerate(os.listdir('newTest')):\n",
    "    index = int(filename.split('.')[0])\n",
    "    file.set_value(index-1, 'label', test_pred[i])\n",
    "    \n",
    "file.to_csv('pred.csv', index=None)\n",
    "file.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
