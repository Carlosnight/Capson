{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_list(path):\n",
    "    import os.path\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    from tensorflow.python.platform import gfile\n",
    "    \n",
    "    images_cats = []\n",
    "    labels_cats = []\n",
    "    images_dogs = []\n",
    "    labels_dogs = []\n",
    "    \n",
    "    extensions = ['jpg']\n",
    "    file_list = []\n",
    "    for extension in extensions:\n",
    "        file_glob = os.path.join(path,'*.' + extension)\n",
    "        file_list.extend(glob.glob(file_glob))\n",
    "        \n",
    "        if not file_list: continue\n",
    "            \n",
    "        for file_name in file_list:\n",
    "            file_name_with_null = file_name.replace(path+\"\\\\\",\"\")\n",
    "            label = file_name_with_null.split(\".\")[0]\n",
    "            if label == 'cat':\n",
    "#                 cats = gfile.FastGFile(file_name, 'rb').read()\n",
    "                images_cats.append(file_name)\n",
    "                labels_cats.append(1)\n",
    "            else:\n",
    "#                 dogs = gfile.FastGFile(file_name, 'rb').read()\n",
    "                images_dogs.append(file_name)\n",
    "                labels_dogs.append(0)\n",
    "    images = np.hstack((images_cats, images_dogs))\n",
    "    labels = np.hstack((labels_cats, labels_dogs))\n",
    "    print(\"laebls:\", labels)\n",
    "        \n",
    "    num_images = len(labels)\n",
    "    print(\"num_images:\", num_images)\n",
    "        \n",
    "    input_data = np.array([images, labels])\n",
    "    input_data = input_data.transpose()\n",
    "    print(\"input_data:\", input_data[0][1])\n",
    "    \n",
    "    np.random.shuffle(input_data)\n",
    "        \n",
    "    input_images = input_data[:, 0]\n",
    "    input_labels = input_data[:, 1]\n",
    "    input_labels = [int(i) for i in input_labels]\n",
    "    \n",
    "    print(\"input_labels:\", input_labels)\n",
    "    print(\"input_images:\", input_images[0])\n",
    "    \n",
    "        \n",
    "    train_images, valid_images, train_labels, valid_labels = train_test_split(input_images, input_labels, test_size=0.25, random_state=0)\n",
    "        \n",
    "    return train_images, train_labels, valid_images, valid_labels\n",
    "    \n",
    "# import matplotlib.pyplot as plt\n",
    "# TRAIN_DATA_PATH = \"C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe\"\n",
    "# train_images, train_labels, valid_images, valid_labels = create_images_list(TRAIN_DATA_PATH)\n",
    "# print(train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(images, labels, weight, height, batch_size):\n",
    "    import numpy as np\n",
    "    images = tf.cast(images, tf.string)\n",
    "    labels = tf.cast(labels, tf.int32)\n",
    "    \n",
    "    input_data = tf.train.slice_input_producer([images, labels])\n",
    "    \n",
    "    image_raw = tf.read_file(input_data[0])\n",
    "    labels = input_data[1]\n",
    "    \n",
    "    # 图像预处理开始\n",
    "    images = tf.image.decode_jpeg(image_raw, channels=3)\n",
    "    # 转换图像张量的类型\n",
    "    images = tf.image.convert_image_dtype(images, dtype=tf.float32)\n",
    "    # 调整图像为神经网络输入层的大小，调整算法随机\n",
    "    images = tf.image.resize_images(images, [weight, height],\n",
    "                                   method=np.random.randint(4))\n",
    "    # 将图像进行随机左右反转\n",
    "    images = tf.image.random_flip_left_right(images)\n",
    "    images = tf.image.per_image_standardization(images)\n",
    "    # 图像预处理完成\n",
    "    print(\"images:\", images)\n",
    "    print(\"labels:\", labels)\n",
    "    \n",
    "    min_after_dequeue = 2000\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    \n",
    "    image_batch, label_batch = tf.train.batch([images, labels],\n",
    "                                   batch_size = batch_size,\n",
    "                                   num_threads = 64,\n",
    "                                   capacity = capacity)\n",
    "    \n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "    return image_batch, label_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image_batch, train):\n",
    "    INPUT_NODE = 268203\n",
    "    OUTPUT_NODE = 2\n",
    "    \n",
    "    IMAGE_SIZE = 299\n",
    "    NUM_CHANNELS = 3\n",
    "    NUM_LABELS = 2\n",
    "    \n",
    "    CONV1_SIZE = 5\n",
    "    CONV1_DEEP = 32\n",
    "    \n",
    "    CONV2_SIZE = 5\n",
    "    CONV2_DEEP = 64\n",
    "    \n",
    "    FC1_SIZE = 128\n",
    "    FC2_SIZE = 64\n",
    "    \n",
    "    # 第一层卷积层\n",
    "    with tf.variable_scope(\"layer1-conv1\"):\n",
    "#         conv1_weights = tf.get_variable(\n",
    "#             \"weight\", [CONV1_SIZE, CONV1_SIZE, NUM_CHANNELS, CONV1_DEEP],\n",
    "#             initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "#          conv1_biases = tf.get_variable(\n",
    "#             \"bias\", [CONV1_DEEP], initializer=tf.constant_initalizer(0.0))\n",
    "        depth = int(list(image_batch.get_shape())[-1])\n",
    "        print(\"depth with conv1:\", depth)\n",
    "        conv1_weights = tf.Variable(\n",
    "            tf.truncated_normal([CONV1_SIZE, CONV1_SIZE, depth, CONV1_DEEP], stddev=0.1))\n",
    "        conv1_biases = tf.Variable(tf.zeros(CONV1_DEEP))\n",
    "        \n",
    "        # 滤波器边长为5，深度为32，步长2，使用全0填充\n",
    "        conv1 = tf.nn.conv2d(\n",
    "            image_batch, conv1_weights, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n",
    "        \n",
    "        print(\"relu1's size:\", relu1)\n",
    "        \n",
    "    # 第二层最大池化层, 滤波器边长2，全0填充，步长2\n",
    "    with tf.name_scope('layer2-pool1'):\n",
    "        pool1 = tf.nn.max_pool(\n",
    "            relu1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        print(\"the size of pool1:\", pool1)\n",
    "        \n",
    "    # 第三层 卷积层\n",
    "    with tf.name_scope(\"layer3-conv2\"):\n",
    "#         conv2_weights = tf.get_variable(\n",
    "#             \"weight\", [CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV2_DEEP],\n",
    "#             intializer=tf.truncated.normal_initializer(stddev=0.1))\n",
    "#         conv2_biases = tf.get_variable(\n",
    "#             \"bias\", [CONV2_DEEP], initializer=tf.constant_initializer(0.0))\n",
    "        conv2_weights = tf.Variable(\n",
    "            tf.truncated_normal([CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV2_DEEP], stddev=0.1))\n",
    "        conv2_biases = tf.Variable(tf.zeros(CONV2_DEEP))\n",
    "        # 滤波器边长为5， 深度64， 步长1， 全0填充\n",
    "        conv2 = tf.nn.conv2d(\n",
    "            pool1, conv2_weights, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n",
    "        \n",
    "        print(\"the size of relu2:\", relu2)\n",
    "    # 第四层 最大池化层\n",
    "    with tf.name_scope(\"layer4-pool2\"):\n",
    "        pool2 = tf.nn.max_pool(\n",
    "            relu2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "        print(\"the size of pool2:\", pool2)\n",
    "    \n",
    "    # 扁平化层\n",
    "    with tf.name_scope(\"layer5-flatten\"):\n",
    "        flatten = tf.layers.Flatten()(pool2)\n",
    "        print(\"the size of flatten:\", flatten)\n",
    "        \n",
    "    # 全连接层\n",
    "    with tf.name_scope(\"layer6-fc1\"):\n",
    "        fc1 = tf.contrib.layers.fully_connected(flatten, FC1_SIZE)\n",
    "        if train: fc1 = tf.nn.dropout(fc1, 0.5)\n",
    "        print(\"the size of fc1:\", fc1)\n",
    "    \n",
    "    # 全连接层\n",
    "    with tf.name_scope(\"layer7-fc2\"):\n",
    "        fc2 = tf.contrib.layers.fully_connected(fc1, FC2_SIZE)\n",
    "        print(\"the size of fc2:\", fc2)\n",
    "        \n",
    "    #输出层\n",
    "    with tf.name_scope(\"layer8-output\"):\n",
    "#         depth = list(fc2.get_shape())[1]\n",
    "#         print(depth)\n",
    "        output_weights = tf.Variable(tf.truncated_normal([FC2_SIZE, NUM_LABELS], stddev=0.1))\n",
    "        output_biases = tf.Variable(tf.zeros(NUM_LABELS))\n",
    "        \n",
    "        logit = tf.add(tf.matmul(fc2, output_weights), output_biases)\n",
    "        print(\"the size of logit:\", logit)\n",
    "    \n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yeyiy\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laebls: [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "num_images: 16\n",
      "input_data: 1\n",
      "input_labels: [1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0]\n",
      "input_images: C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe\\cat.5.jpg\n",
      "images: Tensor(\"div:0\", shape=(299, 299, 3), dtype=float32)\n",
      "labels: Tensor(\"input_producer/Gather_1:0\", shape=(), dtype=int32)\n",
      "images: Tensor(\"div_1:0\", shape=(299, 299, 3), dtype=float32)\n",
      "labels: Tensor(\"input_producer_1/Gather_1:0\", shape=(), dtype=int32)\n",
      "depth with conv1: 3\n",
      "relu1's size: Tensor(\"layer1-conv1/Relu:0\", shape=(64, 150, 150, 32), dtype=float32)\n",
      "the size of pool1: Tensor(\"layer2-pool1/MaxPool:0\", shape=(64, 75, 75, 32), dtype=float32)\n",
      "the size of relu2: Tensor(\"layer3-conv2/Relu:0\", shape=(64, 38, 38, 64), dtype=float32)\n",
      "the size of pool2: Tensor(\"layer4-pool2/MaxPool:0\", shape=(64, 19, 19, 64), dtype=float32)\n",
      "the size of flatten: Tensor(\"layer5-flatten/flatten/Reshape:0\", shape=(64, 23104), dtype=float32)\n",
      "the size of fc1: Tensor(\"layer6-fc1/dropout/mul:0\", shape=(64, 128), dtype=float32)\n",
      "the size of fc2: Tensor(\"layer7-fc2/fully_connected/Relu:0\", shape=(64, 64), dtype=float32)\n",
      "the size of logit: Tensor(\"layer8-output/Add:0\", shape=(64, 2), dtype=float32)\n",
      "train_label_batch: Tensor(\"Reshape:0\", shape=(64,), dtype=int32)\n",
      "logits: Tensor(\"layer8-output/Add:0\", shape=(64, 2), dtype=float32)\n",
      "Step 0, train loss = 0.94, train accuracy = 53.12%\n",
      "**  Step 0, valid loss = 0.78, valid accuracy = 75.00%  **\n",
      "Step 50, train loss = 0.02, train accuracy = 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b0f072413d0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_image_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             _, train_loss, train_acc = sess.run([train_step, loss, accuracy], feed_dict={\n\u001b[1;32m---> 66\u001b[1;33m                                             x: train_images, y:train_labels})\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Step %d, train loss = %.2f, train accuracy = %.2f%%'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "TRAIN_PATH = \"C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe\"\n",
    "TEST_PATH = \"C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe\"\n",
    "train_logs_dir = \"./logs/train\"\n",
    "valid_logs_dir = \"./logs/valid\"\n",
    "\n",
    "N_CLASSES = 2\n",
    "weight = 299\n",
    "height = 299\n",
    "channels = 3\n",
    "batch_size = 64\n",
    "max_step = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "train_images, train_labels, valid_images, valid_labels = \\\n",
    "    create_images_list(TRAIN_PATH)\n",
    "train_image_batch, train_label_batch = make_batch(\n",
    "    train_images, train_labels, weight, height, batch_size)\n",
    "\n",
    "valid_image_batch, valid_label_batch = make_batch(\n",
    "    valid_images, valid_labels, weight, height, batch_size)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, weight, height, channels], name='x')\n",
    "y = tf.placeholder(tf.int64, shape=[batch_size], name='y')\n",
    "\n",
    "logits = inference(x, train=True)\n",
    "\n",
    "print(\"train_label_batch:\", train_label_batch)\n",
    "print(\"logits:\", logits)\n",
    "\n",
    "# loss and optimizer\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "#     logits=logits, labels=train_label_batch))\n",
    "with tf.variable_scope('loss') as scope:\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits\\\n",
    "                        (logits=logits, labels=y)\n",
    "        loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "        tf.summary.scalar(scope.name+'/loss', loss)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#Accuracy\n",
    "# correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "correct_pred = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    summary = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(train_logs_dir, sess.graph)\n",
    "    valid_writer = tf.summary.FileWriter(valid_logs_dir, sess.graph)\n",
    "    \n",
    "    try:\n",
    "        for step in np.arange(max_step):\n",
    "            if coord.should_stop():\n",
    "                break\n",
    "            train_images, train_labels = sess.run(([train_image_batch, train_label_batch]))\n",
    "            _, train_loss, train_acc = sess.run([train_step, loss, accuracy], feed_dict={\n",
    "                                            x: train_images, y:train_labels})\n",
    "            if step % 50 == 0:\n",
    "                print('Step %d, train loss = %.2f, train accuracy = %.2f%%' %(step, train_loss, train_acc*100.0))\n",
    "#                 summary_str = sess.run(summary)\n",
    "#                 train_writer.add_summary(summary_str, step)\n",
    "\n",
    "            if step % 200 == 0 or (step + 1) == max_step:\n",
    "                valid_images, valid_labels = sess.run([valid_image_batch, valid_label_batch])\n",
    "                valid_loss, valid_acc = sess.run([loss, accuracy],\n",
    "                                                 feed_dict={x:valid_images, y:valid_labels})\n",
    "                print('**  Step %d, valid loss = %.2f, valid accuracy = %.2f%%  **' %(step, valid_loss, valid_acc*100.0))\n",
    "#                 summary_str = sess.run(summary)\n",
    "#                 val_writer.add_summary(summary_str, step)\n",
    "\n",
    "            if step % 2000 == 0 or (step + 1) == max_step:\n",
    "                checkpoint_path = os.path.join(train_logs_dir, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step=step)\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"Done!\")\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
