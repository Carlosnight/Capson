{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images_list(path):\n",
    "    import os.path\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    from tensorflow.python.platform import gfile\n",
    "    \n",
    "    images_cats = []\n",
    "    labels_cats = []\n",
    "    images_dogs = []\n",
    "    labels_dogs = []\n",
    "    \n",
    "    extensions = ['jpg']\n",
    "    file_list = []\n",
    "    for extension in extensions:\n",
    "        file_glob = os.path.join(path,'*.' + extension)\n",
    "        file_list.extend(glob.glob(file_glob))\n",
    "        \n",
    "        if not file_list: continue\n",
    "            \n",
    "        for file_name in file_list:\n",
    "            file_name_with_null = file_name.replace(path+\"\\\\\",\"\")\n",
    "            label = file_name_with_null.split(\".\")[0]\n",
    "            if label == 'cat':\n",
    "#                 cats = gfile.FastGFile(file_name, 'rb').read()\n",
    "                images_cats.append(file_name)\n",
    "                labels_cats.append(1)\n",
    "            else:\n",
    "#                 dogs = gfile.FastGFile(file_name, 'rb').read()\n",
    "                images_dogs.append(file_name)\n",
    "                labels_dogs.append(0)\n",
    "    images = np.hstack((images_cats, images_dogs))\n",
    "    labels = np.hstack((labels_cats, labels_dogs))\n",
    "    print(\"laebls:\", labels)\n",
    "        \n",
    "    num_images = len(labels)\n",
    "    print(\"num_images:\", num_images)\n",
    "        \n",
    "    input_data = np.array([images, labels])\n",
    "    input_data = input_data.transpose()\n",
    "    print(\"input_data:\", input_data[0][1])\n",
    "    \n",
    "    np.random.shuffle(input_data)\n",
    "        \n",
    "    input_images = input_data[:, 0]\n",
    "    input_labels = input_data[:, 1]\n",
    "    input_labels = [int(i) for i in input_labels]\n",
    "    \n",
    "    print(\"input_labels:\", input_labels)\n",
    "    print(\"input_images:\", input_images[0])\n",
    "    \n",
    "        \n",
    "    train_images, valid_images, train_labels, valid_labels = train_test_split(input_images, input_labels, test_size=0.25, random_state=0)\n",
    "        \n",
    "    return train_images, train_labels, valid_images, valid_labels\n",
    "    \n",
    "# import matplotlib.pyplot as plt\n",
    "# TRAIN_DATA_PATH = \"C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe\"\n",
    "# train_images, train_labels, valid_images, valid_labels = create_images_list(TRAIN_DATA_PATH)\n",
    "# print(train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(images, labels, weight, height, batch_size):\n",
    "    import numpy as np\n",
    "    images = tf.cast(images, tf.string)\n",
    "    labels = tf.cast(labels, tf.int32)\n",
    "    \n",
    "    input_data = tf.train.slice_input_producer([images, labels])\n",
    "    \n",
    "    image_raw = tf.read_file(input_data[0])\n",
    "    labels = input_data[1]\n",
    "    \n",
    "    # 图像预处理开始\n",
    "    images = tf.image.decode_jpeg(image_raw, channels=3)\n",
    "    # 转换图像张量的类型\n",
    "    images = tf.image.convert_image_dtype(images, dtype=tf.float32)\n",
    "    # 调整图像为神经网络输入层的大小，调整算法随机\n",
    "    images = tf.image.resize_images(images, [weight, height],\n",
    "                                   method=np.random.randint(4))\n",
    "    # 将图像进行随机左右反转\n",
    "    images = tf.image.random_flip_left_right(images)\n",
    "    images = tf.image.per_image_standardization(images)\n",
    "    # 图像预处理完成\n",
    "    print(\"images:\", images)\n",
    "    print(\"labels:\", labels)\n",
    "    \n",
    "    min_after_dequeue = 2000\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    \n",
    "    image_batch, label_batch = tf.train.batch([images, labels],\n",
    "                                   batch_size = batch_size,\n",
    "                                   num_threads = 64,\n",
    "                                   capacity = capacity)\n",
    "    \n",
    "    label_batch = tf.reshape(label_batch, [batch_size])\n",
    "    return image_batch, label_batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image_batch, train):\n",
    "    INPUT_NODE = 268203\n",
    "    OUTPUT_NODE = 2\n",
    "    \n",
    "    IMAGE_SIZE = 299\n",
    "    NUM_CHANNELS = 3\n",
    "    NUM_LABELS = 2\n",
    "    \n",
    "    CONV1_SIZE = 5\n",
    "    CONV1_DEEP = 32\n",
    "    \n",
    "    CONV2_SIZE = 5\n",
    "    CONV2_DEEP = 64\n",
    "    \n",
    "    FC1_SIZE = 128\n",
    "    FC2_SIZE = 64\n",
    "    \n",
    "    # 第一层卷积层\n",
    "    with tf.variable_scope(\"layer1-conv1\"):\n",
    "#         conv1_weights = tf.get_variable(\n",
    "#             \"weight\", [CONV1_SIZE, CONV1_SIZE, NUM_CHANNELS, CONV1_DEEP],\n",
    "#             initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "#          conv1_biases = tf.get_variable(\n",
    "#             \"bias\", [CONV1_DEEP], initializer=tf.constant_initalizer(0.0))\n",
    "        depth = int(list(image_batch.get_shape())[-1])\n",
    "        print(\"depth with conv1:\", depth)\n",
    "        conv1_weights = tf.Variable(\n",
    "            tf.truncated_normal([CONV1_SIZE, CONV1_SIZE, depth, CONV1_DEEP], stddev=0.1))\n",
    "        conv1_biases = tf.Variable(tf.zeros(CONV1_DEEP))\n",
    "        \n",
    "        # 滤波器边长为5，深度为32，步长2，使用全0填充\n",
    "        conv1 = tf.nn.conv2d(\n",
    "            image_batch, conv1_weights, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))\n",
    "        \n",
    "        print(\"relu1's size:\", relu1)\n",
    "        \n",
    "    # 第二层最大池化层, 滤波器边长2，全0填充，步长2\n",
    "    with tf.name_scope('layer2-pool1'):\n",
    "        pool1 = tf.nn.max_pool(\n",
    "            relu1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        print(\"the size of pool1:\", pool1)\n",
    "        \n",
    "    # 第三层 卷积层\n",
    "    with tf.name_scope(\"layer3-conv2\"):\n",
    "#         conv2_weights = tf.get_variable(\n",
    "#             \"weight\", [CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV2_DEEP],\n",
    "#             intializer=tf.truncated.normal_initializer(stddev=0.1))\n",
    "#         conv2_biases = tf.get_variable(\n",
    "#             \"bias\", [CONV2_DEEP], initializer=tf.constant_initializer(0.0))\n",
    "        conv2_weights = tf.Variable(\n",
    "            tf.truncated_normal([CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV2_DEEP], stddev=0.1))\n",
    "        conv2_biases = tf.Variable(tf.zeros(CONV2_DEEP))\n",
    "        # 滤波器边长为5， 深度64， 步长1， 全0填充\n",
    "        conv2 = tf.nn.conv2d(\n",
    "            pool1, conv2_weights, strides=[1,2,2,1], padding=\"SAME\")\n",
    "        relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))\n",
    "        \n",
    "        print(\"the size of relu2:\", relu2)\n",
    "    # 第四层 最大池化层\n",
    "    with tf.name_scope(\"layer4-pool2\"):\n",
    "        pool2 = tf.nn.max_pool(\n",
    "            relu2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "        print(\"the size of pool2:\", pool2)\n",
    "    \n",
    "    # 扁平化层\n",
    "    with tf.name_scope(\"layer5-flatten\"):\n",
    "        flatten = tf.layers.Flatten()(pool2)\n",
    "        print(\"the size of flatten:\", flatten)\n",
    "        \n",
    "    # 全连接层\n",
    "    with tf.name_scope(\"layer6-fc1\"):\n",
    "        fc1 = tf.contrib.layers.fully_connected(flatten, FC1_SIZE)\n",
    "        if train: fc1 = tf.nn.dropout(fc1, 0.5)\n",
    "        print(\"the size of fc1:\", fc1)\n",
    "    \n",
    "    # 全连接层\n",
    "    with tf.name_scope(\"layer7-fc2\"):\n",
    "        fc2 = tf.contrib.layers.fully_connected(fc1, FC2_SIZE)\n",
    "        print(\"the size of fc2:\", fc2)\n",
    "        \n",
    "    #输出层\n",
    "    with tf.name_scope(\"layer8-output\"):\n",
    "#         depth = list(fc2.get_shape())[1]\n",
    "#         print(depth)\n",
    "        output_weights = tf.Variable(tf.truncated_normal([FC2_SIZE, NUM_LABELS], stddev=0.1))\n",
    "        output_biases = tf.Variable(tf.zeros(NUM_LABELS))\n",
    "        \n",
    "        logit = tf.add(tf.matmul(fc2, output_weights), output_biases)\n",
    "        print(\"the size of logit:\", logit)\n",
    "    \n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laebls: [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      "num_images: 16\n",
      "input_data: 1\n",
      "input_labels: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "input_images: C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe\\dog.654.jpg\n",
      "images: Tensor(\"div_27:0\", shape=(299, 299, 3), dtype=float32)\n",
      "labels: Tensor(\"input_producer_30/Gather_1:0\", shape=(), dtype=int32)\n",
      "images: Tensor(\"div_28:0\", shape=(299, 299, 3), dtype=float32)\n",
      "labels: Tensor(\"input_producer_31/Gather_1:0\", shape=(), dtype=int32)\n",
      "depth with conv1: 3\n",
      "relu1's size: Tensor(\"layer1-conv1_13/Relu:0\", shape=(64, 150, 150, 32), dtype=float32)\n",
      "the size of pool1: Tensor(\"layer2-pool1_13/MaxPool:0\", shape=(64, 75, 75, 32), dtype=float32)\n",
      "the size of relu2: Tensor(\"layer3-conv2_13/Relu:0\", shape=(64, 38, 38, 64), dtype=float32)\n",
      "the size of pool2: Tensor(\"layer4-pool2_13/MaxPool:0\", shape=(64, 19, 19, 64), dtype=float32)\n",
      "the size of flatten: Tensor(\"layer5-flatten_13/flatten/Reshape:0\", shape=(64, 23104), dtype=float32)\n",
      "the size of fc1: Tensor(\"layer6-fc1_13/dropout/mul:0\", shape=(64, 128), dtype=float32)\n",
      "the size of fc2: Tensor(\"layer7-fc2_13/fully_connected/Relu:0\", shape=(64, 64), dtype=float32)\n",
      "the size of logit: Tensor(\"layer8-output_13/Add:0\", shape=(64, 2), dtype=float32)\n",
      "train_label_batch: Tensor(\"Reshape_19:0\", shape=(64,), dtype=int32)\n",
      "logits: Tensor(\"layer8-output_13/Add:0\", shape=(64, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "TRAIN_PATH = \"C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe\"\n",
    "TEST_PATH = \"C:/Users/yeyiy/Downloads/Dogs vs Cats/maybe\"\n",
    "train_logs_dir = \"./logs/train\"\n",
    "valid_logs_dir = \"./logs/valid\"\n",
    "\n",
    "N_CLASSES = 2\n",
    "weight = 299\n",
    "height = 299\n",
    "channels = 3\n",
    "batch_size = 64\n",
    "max_step = 10000\n",
    "learning_rate = 0.01\n",
    "\n",
    "train_images, train_labels, valid_images, valid_labels = \\\n",
    "    create_images_list(TRAIN_PATH)\n",
    "train_image_batch, train_label_batch = make_batch(\n",
    "    train_images, train_labels, weight, height, batch_size)\n",
    "\n",
    "valid_image_batch, valid_label_batch = make_batch(\n",
    "    valid_images, valid_labels, weight, height, batch_size)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, weight, height, channels], name='x')\n",
    "y_ = tf.placeholder(tf.int64, shape=[batch_size], name='y')\n",
    "\n",
    "logits = inference(x, train=True)\n",
    "\n",
    "print(\"train_label_batch:\", train_label_batch)\n",
    "print(\"logits:\", logits)\n",
    "\n",
    "# loss and optimizer\n",
    "# loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "#     logits=logits, labels=train_label_batch))\n",
    "with tf.variable_scope('loss') as scope:\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits\\\n",
    "                        (logits=logits, labels=y)\n",
    "        loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "        tf.summary.scalar(scope.name+'/loss', loss)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "#Accuracy\n",
    "# correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "correct_pred = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    summary = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(train_logs_dir, sess.graph)\n",
    "    valid_writer = tf.summary.FileWriter(valid_logs_dir, sess.graph)\n",
    "    \n",
    "    try:\n",
    "        for step in np.arange(max_step):\n",
    "            if coord.should_stop():\n",
    "                break\n",
    "            train_images, train_labels = sess.run(([train_image_batch, train_label_batch]))\n",
    "            _, train_loss, train_acc = sess.run([train_step, loss, accuracy], feed_dict={\n",
    "                                            x: train_images, y:train_labels})\n",
    "            if step % 50 == 0:\n",
    "                print('Step %d, train loss = %.2f, train accuracy = %.2f%%' %(step, train_loss, train_acc*100.0))\n",
    "                summary_str = sess.run(summary)\n",
    "                train_writer.add_summary(summary_str, step)\n",
    "\n",
    "            if step % 200 == 0 or (step + 1) == MAX_STEP:\n",
    "                valid_images, valid_labels = sess.run([valid_image_batch, valid_label_batch])\n",
    "                valid_loss, valid_acc = sess.run([loss, acc],\n",
    "                                                 feed_dict={x:valid_images, y_:valid_labels})\n",
    "                print('**  Step %d, valid loss = %.2f, valid accuracy = %.2f%%  **' %(step, valid_loss, valid_acc*100.0))\n",
    "                summary_str = sess.run(summary)\n",
    "                val_writer.add_summary(summary_str, step)\n",
    "\n",
    "            if step % 2000 == 0 or (step + 1) == MAX_STEP:\n",
    "                checkpoint_path = os.path.join(train_logs_dir, 'model.ckpt')\n",
    "                saver.save(sess, checkpoint_path, global_step=step)\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print(\"Done!\")\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
